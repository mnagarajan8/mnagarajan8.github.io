<!DOCTYPE html>
<html>
<head>
	<title>CS7641 Project</title>
	<style>
		.sidebar {
			width: 100px;
			position: fixed;
			top: 0;
			left: 0;
			bottom: 0;
			background-color: #0E2F44;
		}
	</style>
	<script src="https://code.jquery.com/jquery-3.6.0.min.js"></script>
	<script>
		$(document).ready(function() {
			$('.tab').click(function() {
				var tab_id = $(this).attr('data-tab');

				$('.tab').removeClass('active');
				$('.tab-content').removeClass('active');

				$(this).addClass('active');
				$('#' + tab_id).addClass('active');
			});
		});
	</script>
	.tab {
	  position: relative;
	  z-index: 1;
	}

	.main-content {
	  position: relative;
	  z-index: 0;
	}
</head>
<body>
	<div class="sidebar">
		<ul>
			<li class="tab active" data-tab="tab1">Proposal</li>
			<li class="tab" data-tab="tab2">Midterm Report</li>
			<li class="tab" data-tab="tab3">Final Report</li>
		</ul>
	</div>

	<div class="main-content">
		<div class="tab-content active" id="tab1">
						<h1>CS7641 Project Proposal (Indicators of Heart Disease)</h1>
				      <h2>Introduction, Background, and Dataset</h2>
					<p>Heart disease is currently the number 1 cause of death in the United States causing nearly 700,000 deaths per year. It is largely related to the person(s) current health conditions, as a result we will use machine learning models to identify leading factors resulting in patients’ deaths. Our dataset accounts for leading factors like BMI, smoking history, and sex which are currently identified as factors leading to heart disease.</p>
					      <p>The dataset we are using comes from the CDC and is a major part of the Behavioral Risk Factor Surveillance System (BRFSS), which conducts annual telephone surveys to gather data on the health status of U.S. residents.</p>
				  <p>Source of Data: <a href="https://www.cdc.gov/brfss/annual_data/annual_2020.html">click here</a></p>
				  <p>Dataset Link (Kaggle): <a href="https://www.kaggle.com/datasets/kamilpytlak/personal-key-indicators-of-heart-disease">click here</a></p>

				<h2>Methods</h2>
				  <li>Preprocessing</li>
				  <ul>
				    <li>We will start by partitioning our dataset such that 90% of our data points will be used as training data and 10% as test data. We will convert all of our features that are binary from ‘yes’ and ‘no’ to 1’s and 0’s respectively, and all categorical data such as age ranges will be processed into integer equivalents (i.e. 50-54 = 0, 55-59 = 1, etc.) From there we will use Principal Component Analysis (PCA) to reduce the dimensionality of features.</li>
				  <li>Unsupervised</li>
				     </ul>
				  <ul>
				    <li>We plan to analyze our data by first using the K-means algorithm. After receiving cluster assignments we will determine the cluster strength of each component through distortion value. We will analyze this metric using the elbow method to receive the optimal cluster count (k). We will then move on to using more complicated algorithms like GMM and DBScan with SMOTE in the case our data is unbalanced.</li>
				     </ul>
				  <li>Supervised</li>
				  <ul>
				    <li>We will first use Decision Tree classifiers and Deep Neural Networks (DNN) to compare test results of predicting heart disease with our other models by tuning various hyperparameters. We will then move on to SVM with XGBoost as this is prominent in some research papers.
			</li>
				    </ul>

			      <h2>Potential Results and Discussion</h2>
			      <li>Unsupervised</li>
				  <ul>
				    <li>We expect the unsupervised models to produce clusters that we may examine to discover commonalities. We anticipate finding clusters of cases of heart disease that are related (e.g., share BMI or Mental Health), as well as other clusters that are less visible and call for more investigation. We want to utilize PCA to reduce the number of dimensions and only take into account the most important features.</li>
			      </ul>
			      <li>Supervised</li>
				  <ul>
				    <li>Our supervised models are expected to be trained to predict whether a patient has heart disease or not based on a set of features such as age and smoking status to identify which features are the most important predictors of heart disease.
			</li>
			      </ul>


			      <h2>Timeline</h2>
			      
			      
			      <h2>Contribution Table</h2>
			      
			      
			      <h2>References</h2>
			      <li>Goel, R. (2021). Heart disease prediction using various algorithms of machine learning. SSRN Electronic Journal. https://doi.org/10.2139/ssrn.3884968</li>
			      <li>Jindal, H., Agrawal, S., Khera, R., Jain, R., & Nagrath, P. (2021). Heart disease prediction using machine learning algorithms. IOP Conference Series: Materials Science and Engineering, 1022(1), 012072. https://doi.org/10.1088/1757-899x/1022/1/012072</li>
			      <li>Nagavelli, U., Samanta, D., & Chakraborty, P. (2022). Machine learning technology-based heart disease detection models. Journal of Healthcare Engineering, 2022, 1–9. https://doi.org/10.1155/2022/7351061</li>

          
      
     </div>
		<div class="tab-content" id="tab2">
			<h1>CS7641 Project Midterm Report (Indicators of Heart Disease)</h1>
			
			<h2>Introduction/Background</h2>
			<p>Heart disease is currently the number 1 cause of death in the United States causing nearly 700,000 deaths per year. It is largely related to the person(s) current health conditions, as a result we will use machine learning models to identify leading factors resulting in positive diagnoses and also see if we can accurately predict subpopulations that either have or are privy to developing heart disease.</p>
			<p>Much work has been done in this areas using various techniques on various datasets containing data on various potential heart disease factors. Rati Goel, for example, used 6 different algorithms on a dataset with data on things such as cholesterol and blood pressure[1].</p>
			
			<h2>Problem Definition</h2>
			<p>Identifying the types of people that are likely to have heart disease and the primary factors can be valuable in developing treatments and in early detection so that we can better monitor the health of those at risk. We hope to add onto the body of work that already exists in this specific field of research.</p>
		
			<h2>Dataset</h2>
			<h3>About the Dataset</h3>
			<p>The dataset we are using comes from the CDC and is a major part of the Behavioral Risk Factor Surveillance System (BRFSS), which conducts annual telephone surveys to gather data on the health status of U.S. residents. This dataset accounts for leading factors like BMI, smoking history, and sex which are currently identified as factors leading to heart disease.The following is a sample of raw data from the dataset:<\p>
			<ADD IMAGE>
			<p>Source of Data: <a href="https://www.cdc.gov/brfss/annual_data/annual_2020.html">click here</a></p>
			<p>Dataset Link (Kaggle): <a href="https://www.kaggle.com/datasets/kamilpytlak/personal-key-indicators-of-heart-disease">click here</a></p>
				
			<h3>Data Cleaning/Pre-processing</h3>
			<p>Overall, this particular dataset had great usability, with no null entries/missing data. Therefore, we did not have to deal with this issue. We had to perform the following on the dataset for cleaning:</p>
				<li>Remove Duplicate Columns</li>
				<ul>
					<li>As a result, 18078 rows were dropped</li>
				</ul>
			<p>For pre-processing, by looking at the data we can see there are a lot of categorical features. To solve this issue we created our own defined mappings along with sklearn’s LabelEncoder. The same snippet of raw data now looks like:</p>
				<ADD IMAGE>
			
			<h2>Post-processing Visualizations</h2>
			<p>Following the cleaning techniques used, we made visuals to gain insight into the distribution of all the features.</p>
			<p>Catagorical features:</p> 
					<ADD IMAGE>
			<p>Continuous features:</p>
					<ADD IMAGE>
			<p>We also thought it was valuable to produce a correlation table between the features:</p>
					<ADD IMAGE>
			
						
			<h2>Data Imbalance</h2>
			<p>For the class feature “HeartDisease”, previous visuals indicate that there is some amount of class imbalance. We used a couple of methods to solve this issue</p>
			<li>Downsampling the Majority Class</li>
			<li>SMOTE-NC</li>
				<ul>
					<li>SMOTE (Synthetic Minority Over-sampling Technique) creates synthetic samples by interpolating between existing minority samples in the feature space. It randomly selects a minority sample and creates new synthetic samples along the line segments connecting it to its k nearest neighbors. SMOTE-NC is a version of SMOTE that is able to deal with the combination of both categorical and numerical features</li>
				</ul>
			<p>Through the use of the above techniques, we evened out the target class equally 50-50. We will be comparing the differences in model accuracy that result from using an unbalanced dataset and the methods mentioned above.</p>
			
						
			<h2>Feature Reduction</h2>
						
			<h3>PCA</h3>
			<p>PCA (Principal Component Analysis) is a popular dimensionality reduction technique used to transform high-dimensional datasets into a lower-dimensional space. It does this by identifying the most important features that explain the majority of the variance in the data. The table below shows the percent variance captured by finding 2 and 3 principal components:</p>
						<ADD TABLE IMAGE>
			<p>It seems clear that we should be using minimally 3 principle components when training our unsupervised learning models. The following are what the PCAs for each dataset type when downsampling to 1000 points for the purpose of visuals:</p>
							<ADD 3 IMAGES>
			
			<h2>Methods (So Far)</h2>
			<h3>Unsupervised</h3>
			<li>KMEANS</li>
			<p>We started working with KMeans because it is quite a simple algorithm that can potentially tell us a lot about the data that we have. We will be looking at our results through two lenses. First we will set the number of clusters to 2, as this is representative of our binary target feature. We will then see how the clustering of k=2 can match up with our classification feature. Though from looking at previous PCA visualizations, there is likely not going to be good accuracy. We will also use the Elbow Method to find the optimal number of clusters and run cluster analysis on it to see what kind of features result in certain clusters. Experimentally, we will run all of these with our 3 separate datasets (Unbalanced, Downsample Majority, SMOTE-NC).</p>
			
			<h3>Supervised</h3>
			<li>LOGISTIC REGRESSION</li>
			<p>Logistic Regression was a prominent algorithm that we saw for general classification of Heart Disease. There are a couple of parameters that need to be defined to use sklearn’s Logistic Regression. We will be using l2 regularization for penalty, Stochastic Average Gradient Decent for the solver, and 1 for the inverse regularization strength. We will again be evaluating the model’s performance using out 3 datasets (Unbalanced, Downsample Majority, SMOTE-NC) as we want to see whether handling this class imbalance is necessary or not and if any method is better than another.</p>
					
			
			<h2>Results/Discussion</h2>
			<h3>Supervised</h3>
			<li>KMEANS</li>
			<p>First, we ran KMeans on our 3 separate datasets (Unbalanced, Downsample Majority, SMOTE-NC) after running PCA on them while setting the number of clusters to 2. This is what the resulting clusterings look like per dataset:</p>
				<ADD 3 IMAGES>
			<p>We evaluated the clustering using Silhouette Coefficients, which were:</p>
					<ADD TABLE IMAGE>
			<p>Generally, we can say that the clusters had average to above-average separation. We then wanted to see how well these clusters mapped to the target feature which was whether the person had Heart Disease or not. We mapped the points in these clusters back to the target feature and found the following percentages of points correctly classified.</p>
						<ADD TABLE IMAGE>
			<p>We can see that the unbalanced dataset has a significant percentage of properly classified points. However, because we only have 2 clusters here, and there is class imbalance, it is potentially skewed so the statistic may not too helpful in making any conclusions. The other two datasets however are balanced and do not have the same issues. From the table these percentages indicate that it does a little better than a coin toss. This may indicate that the feature with high variance that get captured by PCA are not key features in determining the target feature. We then did more cluster analysis on the features that might have differentiated the two clusters. We did this by linking the clusters back to their original dataset and averaging the values per feature per cluster. We chose to focus on the Downsample Majority dataset alone as an example.</p>
						<ADD TABLE IMAGE>
			<p>From this, the differences that pop out immediately are with the PhysicalHealth and MentalHealth features. They are the features that are most different per cluster. These features might vary the most but probably are not indicative of anything related to the target feature.</p>
			<p>Next, we ran KMeans again but used the Elbow Method to find the optimal number of clusters. It seemed from the resulting graphs that 4 was generally a good number across datasets. This is the graph from using the Elbow Method on the Downsample Majority dataset:</p>
							<ADD IMAGE>
								
			<p>We decided to then run KMeans with 4 clusters on just the Downsample Majority dataset. The clustering result looked like:</p>
							<ADD IMAGE>
			<p>The Silhouette Coefficient for this clustering was .590 which was similar to the coefficient when there were 2 clusters. We again wanted to see what features were similar in each cluster. Repeating the previous clustering analysis, we got:</p>
								<ADD TABLE IMAGE>
			
			<p>From the results we can see it was still a combination of the same features (PhysicalHealth and MentalHealth) that stood out the most as differentiators, while Stroke also seemed to vary but to a lesser extent. We can generally draw the same conclusions as before. It might be useful to remove these columns or decrease their range so that it is has less of an effect on clustering as a whole.</p>
									
			<h3>Supervised Learning</h3>
			<li>LOGISTIC REGRESION</li>
			<p>As previously stated, we ran Logistic Regression on our 3 datasets (Unbalanced, Downsample Majority, SMOTE-NC) using l2 regularization for penalty, Stochastic Average Gradient Decent for the solver, and 1 for the inverse regularization strength. We also set the max iterations to 200 to ensure model convergence. After running Logistic Regression on our 3 datasets, we had the following results:</p>
								<ADD TABLE IMAGE>
			<p>Given the similarities between train and test accuracy across the board, we can say our models generalize well. Here are the confusion matrices for the 3 datasets in percentage form for the number of points in each category divided by the total number of points:</p>
								<ADD 3 IMAGES>
			<p>Overall, we found the unbalanced dataset far outperformed the balanced datasets for Logistic Regression.</p>
			
			<h2>Contribution Table</h2>
			<ADD IMAGE>
				
			<h2>References</h2>
			<li>Goel, R. (2021). Heart disease prediction using various algorithms of machine learning. SSRN Electronic Journal. https://doi.org/10.2139/ssrn.3884968</li>
			<li>Jindal, H., Agrawal, S., Khera, R., Jain, R., & Nagrath, P. (2021). Heart disease prediction using machine learning algorithms. IOP Conference Series: Materials Science and Engineering, 1022(1), 012072. https://doi.org/10.1088/1757-899x/1022/1/012072</li>
			<li>Nagavelli, U., Samanta, D., & Chakraborty, P. (2022). Machine learning technology-based heart disease detection models. Journal of Healthcare Engineering, 2022, 1–9. https://doi.org/10.1155/2022/7351061</li>

				
		
		
		
		
		
		
		</div>
		<div class="tab-content" id="tab3">
			<h2>Tab 3 Content</h2>
			<p>This is the content for Tab 3.</p>
		</div>
	</div>
</body>
</html>

